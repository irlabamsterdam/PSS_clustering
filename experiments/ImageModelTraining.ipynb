{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Feature Extractor code VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code required to train the VGG model from the Wiedemann paper on the dataset presented in the paper, with code to extract the finetuned vectors from the model. Please be a aware that the training can take quite some time, it took as approximately 6 hours on a decent GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These fuctions assume that you have the data already downloaded, with a folder with the PNG images in the data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FEtKIS5TaO_l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "\n",
    "%run ../utils/metricutils.py\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))\n",
    "\n",
    "class ImageModelWiedemann:\n",
    "    def __init__(self, learning_rate=0.00001):\n",
    "\n",
    "        # We use the VGG16 model pretrained on the imagenet corpus\n",
    "        # As the basis of our network.\n",
    "        model_vgg16 = VGG16(weights='imagenet', include_top=False,\n",
    "                            input_shape=(300, 300, 3))\n",
    "\n",
    "        # We don't want to train the first 13 layers of the VGG16 model\n",
    "        # We will add our own tower to this later. It is common in the literature\n",
    "        # To only freeze the first 4 of the 5 convolutional layers so that\n",
    "        # the network can still learn to adjust some of the filters to specifics\n",
    "        # of the dataset\n",
    "        for l in model_vgg16.layers[:13]:\n",
    "            l.trainable = False\n",
    "\n",
    "        top_model = Flatten()(model_vgg16.output)\n",
    "        drop1 = Dropout(0.5)(top_model)\n",
    "        dense1 = Dense(512)(drop1)\n",
    "        relu1 = LeakyReLU()(dense1)\n",
    "        drop2 = Dropout(0.5)(relu1)\n",
    "        dense2 = Dense(256)(drop2)\n",
    "        relu2 = LeakyReLU()(dense2)\n",
    "\n",
    "        # After the output of the model, we pass the output through\n",
    "        # A final linear layer and a sigmoid to obtain values for prediction\n",
    "        model_output = Dense(1, activation=\"sigmoid\")(relu2)\n",
    "\n",
    "        model = Model(model_vgg16.input, model_output)\n",
    "        # Set up the optimzation steps as described in the original\n",
    "        # wiedemann paper.\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Nadam(learning_rate=learning_rate),\n",
    "                      metrics=['AUC'])\n",
    "\n",
    "        self.intermediate_activation = Model(model_vgg16.input, dense1)\n",
    "        self.intermediate_activation.compile()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, train_data, num_epochs=20):\n",
    "        self.model.fit(train_data, epochs=num_epochs)\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        y_predict = self.model.predict(test_data, verbose=True)\n",
    "        return y_predict\n",
    "\n",
    "\n",
    "def prepare_df_for_model(dataframe):\n",
    "    dataframe['png'] = dataframe.name + '-' + dataframe.page.astype(str) + '.png'\n",
    "    dataframe['label'] = dataframe['label'].astype(str)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def prepare_test_streams(test_subdataframe, png_folder,\n",
    "                         batch_size):\n",
    "\n",
    "    subtest_generator = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input).flow_from_dataframe(\n",
    "        dataframe=test_subdataframe,\n",
    "        directory=png_folder,\n",
    "        x_col='png',\n",
    "        y_col='label',\n",
    "        target_size=(300, 300),\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        validate_filenames=True,\n",
    "    )\n",
    "\n",
    "    return subtest_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63815 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataframe = prepare_df_for_model(pd.read_csv('../data/dataframes/train.csv'))\n",
    "test_dataframe = prepare_df_for_model(pd.read_csv('../data/dataframes/test.csv'))\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input).flow_from_dataframe(\n",
    "    dataframe=train_dataframe,\n",
    "    directory='../data/images/train/',\n",
    "    x_col='png',\n",
    "    y_col='label',\n",
    "    target_size=(300, 300),\n",
    "    class_mode='binary',\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validate_filenames=True)\n",
    "\n",
    "# We either want to train our own model and save it, or use a\n",
    "# Model we trained ourselves, and only run the prediction step.\n",
    "\n",
    "# Set the model\n",
    "model = ImageModelWiedemann(learning_rate=0.00001)\n",
    "# Train the model\n",
    "model.train(train_data=train_gen, num_epochs=20)\n",
    "# Save the model\n",
    "model.model.save('../trained_VGG16_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Feature Vectors from the VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjjSEZyjas2d"
   },
   "source": [
    "Once we have trained the VGG16 model, we can now load it and use to obtain the finetuned vectors for the clustering and classification methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bu4Po_wfa0FH"
   },
   "outputs": [],
   "source": [
    "def get_vectors_from_model(mode=\"finetuned\"):\n",
    "    assert mode in [\"pretrained\", \"finetuned\"]\n",
    "    \n",
    "    if mode == 'pretrained':\n",
    "        model = VGG16(weights = 'imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "    else:\n",
    "        model = load_model('../data/trained_VGG16_model')\n",
    "    \n",
    "    layer_name = 'dense'\n",
    "    model_top = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "    model_input = prepare_df_for_model(pd.read_csv('../data/dataframes/test.csv'))\n",
    "\n",
    "    for doc_id, stream in tqdm(model_input.groupby('name')):\n",
    "        stream['page'] = stream['page'].astype(int)\n",
    "        sorted_stream = stream.sort_values(by='page')\n",
    "\n",
    "        test_data = prepare_test_streams(sorted_stream, '../data/images/test',\n",
    "                                       256)\n",
    "        vectors = model_top.predict(test_data)\n",
    "    if mode == \"pretrained\":\n",
    "        np.save('../data/pretrained_vectors.npy', vectors)\n",
    "    elif mode == \"finetuned\":\n",
    "        np.save('../data/finetuned_vectors.npy', vectors)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_vectors_from_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
